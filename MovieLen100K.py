# -*- coding: utf-8 -*-
"""Movie Recommendation System Using XAI - Initial Implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nE-U9eZ--MqvGTwNdw9zvAht4DvQqZPP

**Phase 0: Setup & Reproducibility**
"""

!pip install pandas numpy scikit-surprise matplotlib seaborn plotly scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import random
import os

# Set random seeds for reproducibility
np.random.seed(42)
random.seed(42)

print("‚úÖ Phase 0 Complete: Environment setup with reproducibility")

"""**Phase 1: Data Collection & Enrichment**"""

# Load MovieLens 100k Dataset
def load_movielens_data():
  # Load ratings data
  ratings_col = ["user_id", "movie_id", "rating", "timestamp"]
  ratings = pd.read_csv('/content/drive/MyDrive/ml-100k/u.data', sep='\t', names=ratings_col)
  # Load movie data
  movies_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']
  movies = pd.read_csv('/content/drive/MyDrive/ml-100k/u.item', sep='|', names=movies_cols, encoding='latin-1')
  # Load user data
  users_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']
  users = pd.read_csv('/content/drive/MyDrive/ml-100k/u.user', sep='|', names=users_cols)

  # Load Genre Information
  genres = [
      "unknown", "Action", "Adventure", "Animation", "Children's", "Comedy",
      "Crime", "Documentary", "Drama", "Fantasy", "Film-Noir", "Horror",
      "Musical", "Mystery", "Romance", "Sci-Fi", "Thriller", "War", "Western"
  ]

  # Load the actual genre matrix
  genre_matrix = pd.read_csv('/content/drive/MyDrive/ml-100k/u.item', sep='|',names=movies_cols + genres, encoding='latin-1')

  return ratings, movies, users, genre_matrix, genres

# Load the data
ratings, movies, users, genre_matrix, genres = load_movielens_data()

print("üìä Dataset Overview:")
print(f"Ratings: {ratings.shape}")
print(f"Movies: {movies.shape}")
print(f"Users: {users.shape}")
print(f"Genres: {len(genres)}")

# Display sample data
print("\nüìà Sample Ratings:")
print(ratings.head())
print("\nüé¨ Sample Movies:")
print(movies[['movie_id', 'title', 'release_date']].head())
print("\nüë• Sample Users:")
print(users.head())

# Create unified item table with genres
def create_unified_item_table(movies, genre_matrix, genres):
  # Extract year from title
  movies['year'] = movies['title'].str.extract(r'\((\d{4})\)')
  movies['year'] = pd.to_numeric(movies['year'], errors='coerce')

  # Clean title (remove year)
  movies['clean_title'] = movies['title'].str.replace(r'\(\d{4}\)', '').str.strip()

  # Create unified item table with genres
  item_table = movies[['movie_id', 'clean_title', 'year']].copy()

  # Add genre columns
  for genre in genres:
        item_table[genre] = genre_matrix[genre]

  return item_table

# Fix: Reconstruct movies DataFrame from genre_matrix as it was loaded correctly
# This ensures that 'title' and other columns are properly separated strings.
movies_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']
movies_fixed = genre_matrix[movies_cols].copy()

# Create unified item table using the fixed movies DataFrame
item_table = create_unified_item_table(movies_fixed, genre_matrix, genres)
print("üéØ Unified Item Table:")
print(item_table.head())

# Preprocess ratings - filter cold users/items
def preprocess_ratings(ratings, min_ratings_per_user=5, min_ratings_per_movie=5):
    print(f"Original ratings shape: {ratings.shape}")

    # Filter users with at least min_ratings_per_user
    user_rating_counts = ratings['user_id'].value_counts()
    active_users = user_rating_counts[user_rating_counts >= min_ratings_per_user].index
    ratings = ratings[ratings['user_id'].isin(active_users)]

    # Filter movies with at least min_ratings_per_movie
    movie_rating_counts = ratings['movie_id'].value_counts()
    popular_movies = movie_rating_counts[movie_rating_counts >= min_ratings_per_movie].index
    ratings = ratings[ratings['movie_id'].isin(popular_movies)]

    print(f"After filtering cold users/items: {ratings.shape}")
    print(f"Remaining users: {ratings['user_id'].nunique()}")
    print(f"Remaining movies: {ratings['movie_id'].nunique()}")

    return ratings

filtered_ratings = preprocess_ratings(ratings)

# Feature extraction
def extract_features(ratings, item_table, users):
    # Content features: genre vectors
    genre_cols = [col for col in item_table.columns if col in genres]
    movie_genres = item_table[['movie_id'] + genre_cols]

    # User features: age, gender, occupation
    user_features = users.copy()

    # Convert gender to numeric
    user_features['gender'] = user_features['gender'].map({'M': 0, 'F': 1})

    # Convert occupation to one-hot encoding
    occupation_dummies = pd.get_dummies(user_features['occupation'], prefix='occupation')
    user_features = pd.concat([user_features, occupation_dummies], axis=1)

    # Behavioral features: user genre preferences
    user_movie_ratings = pd.merge(ratings, movie_genres, on='movie_id')

    # Calculate user genre preferences (average rating per genre)
    user_genre_prefs = []
    for user_id in user_movie_ratings['user_id'].unique():
        user_data = user_movie_ratings[user_movie_ratings['user_id'] == user_id]
        genre_prefs = {'user_id': user_id}

        for genre in genre_cols:
            genre_ratings = user_data[user_data[genre] == 1]['rating']
            genre_prefs[f'pref_{genre}'] = genre_ratings.mean() if len(genre_ratings) > 0 else 0

        user_genre_prefs.append(genre_prefs)

    user_genre_prefs_df = pd.DataFrame(user_genre_prefs)
    user_features = pd.merge(user_features, user_genre_prefs_df, on='user_id', how='left')

    return user_features, movie_genres, genre_cols

user_features, movie_genres, genre_cols = extract_features(filtered_ratings, item_table, users)
print("üéØ Feature Extraction Complete:")
print(f"User features shape: {user_features.shape}")
print(f"Movie genres shape: {movie_genres.shape}")

# Save processed data
# Create directories
os.makedirs('/content/drive/MyDrive/data/processed', exist_ok=True)
os.makedirs('/content/drive/MyDrive/data/raw', exist_ok=True)

# Save processed data
filtered_ratings.to_csv('/content/drive/MyDrive/data/processed/ratings_processed.csv', index=False)
item_table.to_csv('/content/drive/MyDrive/data/processed/movies_processed.csv', index=False)
user_features.to_csv('/content/drive/MyDrive/data/processed/users_processed.csv', index=False)
movie_genres.to_csv('/content/drive/MyDrive/data/processed/movie_genres.csv', index=False)

print("üíæ Phase 1 Complete: Data processed and saved")

"""**Phase 2: Baselines & Exploratory Data Analysis**"""

# Exploratory Data Analysis (EDA)
def perform_eda(ratings, movies, users):
    print("üìä EXPLORATORY DATA ANALYSIS")
    print("=" * 50)

    # Rating distribution
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    ratings['rating'].hist(bins=10, alpha=0.7, color='skyblue')
    plt.title('Rating Distribution')
    plt.xlabel('Rating')
    plt.ylabel('Frequency')

    # User rating counts
    plt.subplot(1, 3, 2)
    user_rating_counts = ratings['user_id'].value_counts()
    user_rating_counts.hist(bins=50, alpha=0.7, color='lightgreen')
    plt.title('Ratings per User')
    plt.xlabel('Number of Ratings')
    plt.ylabel('Number of Users')

    # Movie rating counts
    plt.subplot(1, 3, 3)
    movie_rating_counts = ratings['movie_id'].value_counts()
    movie_rating_counts.hist(bins=50, alpha=0.7, color='salmon')
    plt.title('Ratings per Movie')
    plt.xlabel('Number of Ratings')
    plt.ylabel('Number of Movies')

    plt.tight_layout()
    plt.show()

    # Basic statistics
    print(f"Total ratings: {len(ratings)}")
    print(f"Total users: {ratings['user_id'].nunique()}")
    print(f"Total movies: {ratings['movie_id'].nunique()}")
    print(f"Average rating: {ratings['rating'].mean():.2f}")
    print(f"Sparsity: {1 - len(ratings)/(ratings['user_id'].nunique() * ratings['movie_id'].nunique()):.4f}")

    # Top genres analysis
    genre_counts = item_table[genres].sum().sort_values(ascending=False)
    print("\nüé≠ Top Genres:")
    for genre, count in genre_counts.head(10).items():
        print(f"  {genre}: {count} movies")

perform_eda(filtered_ratings, movies, users)

# Baseline Models
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from collections import defaultdict

# Split data into train/test
train_ratings, test_ratings = train_test_split(
    filtered_ratings, test_size=0.2, random_state=42, stratify=filtered_ratings['user_id']
)

print(f"Train ratings: {train_ratings.shape}")
print(f"Test ratings: {test_ratings.shape}")

# Popularity Baseline
def popularity_baseline(train_ratings, k=10):
    # Calculate average rating for each movie
    movie_avg_ratings = train_ratings.groupby('movie_id')['rating'].agg(['mean', 'count'])
    movie_avg_ratings = movie_avg_ratings.sort_values(['mean', 'count'], ascending=[False, False])

    # Get top K popular movies
    top_k_movies = movie_avg_ratings.head(k).index.tolist()
    return top_k_movies, movie_avg_ratings

top_popular_movies, movie_stats = popularity_baseline(train_ratings)
print("üî• Popularity Baseline - Top 10 Movies:")
for i, movie_id in enumerate(top_popular_movies[:10], 1):
    movie_title = item_table[item_table['movie_id'] == movie_id]['clean_title'].iloc[0]
    avg_rating = movie_stats.loc[movie_id, 'mean']
    print(f"{i}. {movie_title} (Rating: {avg_rating:.2f})")

# Item-based Collaborative Filtering
def item_based_cf(train_ratings, item_table, genre_cols, user_id, k=10):
    # Create user-item matrix
    user_item_matrix = train_ratings.pivot_table(
        index='user_id', columns='movie_id', values='rating'
    ).fillna(0)

    # Get movies the user has rated
    user_rated_movies = train_ratings[train_ratings['user_id'] == user_id]['movie_id'].tolist()

    if not user_rated_movies:
        return popularity_baseline(train_ratings, k)[0]

    # Calculate movie similarities based on genres
    movie_features = item_table[['movie_id'] + genre_cols].set_index('movie_id')
    movie_similarity = cosine_similarity(movie_features)
    movie_similarity_df = pd.DataFrame(
        movie_similarity,
        index=movie_features.index,
        columns=movie_features.index
    )

    # Get similar movies
    similar_movies = {}
    for rated_movie in user_rated_movies:
        if rated_movie in movie_similarity_df.index:
            similarities = movie_similarity_df[rated_movie].sort_values(ascending=False)
            # Exclude the movie itself and get top similar
            for movie_id, sim_score in similarities.items():
                if movie_id != rated_movie and movie_id not in user_rated_movies:
                    if movie_id not in similar_movies:
                        similar_movies[movie_id] = 0
                    similar_movies[movie_id] += sim_score

    # Sort by similarity score and get top K
    recommended_movies = sorted(similar_movies.items(), key=lambda x: x[1], reverse=True)[:k]
    return [movie_id for movie_id, score in recommended_movies]

# Test item-based CF for a sample user
sample_user = train_ratings['user_id'].iloc[0]
cf_recommendations = item_based_cf(train_ratings, item_table, genre_cols, sample_user)

print(f"üéØ Item-Based CF Recommendations for User {sample_user}:")
for i, movie_id in enumerate(cf_recommendations[:10], 1):
    movie_title = item_table[item_table['movie_id'] == movie_id]['clean_title'].iloc[0]
    print(f"{i}. {movie_title}")

# Content-based Filtering
def content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features, k=10):
    # Get user's genre preferences
    user_prefs = user_features[user_features['user_id'] == user_id]
    if user_prefs.empty:
        return popularity_baseline(train_ratings, k)[0]

    # Create user preference vector
    pref_cols = [f'pref_{genre}' for genre in genre_cols]
    user_pref_vector = user_prefs[pref_cols].values.flatten()

    # Calculate similarity between user preferences and movie genres
    movie_scores = []
    for _, movie in item_table.iterrows():
        movie_genre_vector = movie[genre_cols].values
        similarity = np.dot(user_pref_vector, movie_genre_vector) / (
            np.linalg.norm(user_pref_vector) * np.linalg.norm(movie_genre_vector) + 1e-8
        )
        movie_scores.append((movie['movie_id'], similarity))

    # Sort by similarity and get top K
    movie_scores.sort(key=lambda x: x[1], reverse=True)

    # Filter out movies user has already rated
    rated_movies = train_ratings[train_ratings['user_id'] == user_id]['movie_id'].tolist()
    recommendations = [movie_id for movie_id, score in movie_scores if movie_id not in rated_movies][:k]

    return recommendations

# Test content-based filtering for a sample user
content_recommendations = content_based_filtering(
    sample_user, train_ratings, item_table, genre_cols, user_features
)

print(f"üé≠ Content-Based Recommendations for User {sample_user}:")
for i, movie_id in enumerate(content_recommendations[:10], 1):
    movie_title = item_table[item_table['movie_id'] == movie_id]['clean_title'].iloc[0]
    print(f"{i}. {movie_title}")

# Offline Evaluation
def evaluate_baselines(train_ratings, test_ratings, item_table, genre_cols, user_features, k=10):
    metrics = {
        'popularity': {'precision': [], 'recall': [], 'hit_rate': []},
        'item_cf': {'precision': [], 'recall': [], 'hit_rate': []},
        'content': {'precision': [], 'recall': [], 'hit_rate': []}
    }

    # Get popular movies for popularity baseline
    popular_movies, _ = popularity_baseline(train_ratings, k=100)

    # Sample users for evaluation (for speed)
    test_users = test_ratings['user_id'].unique()[:50]

    for user_id in test_users:
        user_test_movies = test_ratings[test_ratings['user_id'] == user_id]['movie_id'].tolist()

        if not user_test_movies:
            continue

        # Popularity baseline
        pop_recs = popular_movies[:k]
        pop_hits = len(set(pop_recs) & set(user_test_movies))
        metrics['popularity']['precision'].append(pop_hits / k)
        metrics['popularity']['recall'].append(pop_hits / len(user_test_movies))
        metrics['popularity']['hit_rate'].append(1 if pop_hits > 0 else 0)

        # Item-based CF
        try:
            cf_recs = item_based_cf(train_ratings, item_table, genre_cols, user_id, k)
            cf_hits = len(set(cf_recs) & set(user_test_movies))
            metrics['item_cf']['precision'].append(cf_hits / k)
            metrics['item_cf']['recall'].append(cf_hits / len(user_test_movies))
            metrics['item_cf']['hit_rate'].append(1 if cf_hits > 0 else 0)
        except:
            continue

        # Content-based
        try:
            content_recs = content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features, k)
            content_hits = len(set(content_recs) & set(user_test_movies))
            metrics['content']['precision'].append(content_hits / k)
            metrics['content']['recall'].append(content_hits / len(user_test_movies))
            metrics['content']['hit_rate'].append(1 if content_hits > 0 else 0)
        except:
            continue

    # Calculate average metrics
    results = {}
    for model in metrics:
        if metrics[model]['precision']:
            results[model] = {
                'Precision@K': np.mean(metrics[model]['precision']),
                'Recall@K': np.mean(metrics[model]['recall']),
                'HitRate@K': np.mean(metrics[model]['hit_rate'])
            }

    return pd.DataFrame(results).T

# Evaluate baselines
print("üìä Evaluating Baseline Models...")
baseline_results = evaluate_baselines(train_ratings, test_ratings, item_table, genre_cols, user_features)
print("\nüéØ Baseline Performance Metrics:")
print(baseline_results.round(4))

"""**Phase 3: Hybrid Model Framework**"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# Simple Neural Collaborative Filtering
class NCFDataset(Dataset):
  def __init__(self, ratings, num_users, num_movies):
    self.ratings = ratings
    self.num_users = num_users
    self.num_movies = num_movies

  def __len__(self):
    return len(self.ratings)

  def __getitem__(self, index):
    row = self.ratings.iloc[index]
    user_id = row['user_idx'] # Use the pre-mapped 0-based index
    movie_id = row['movie_idx'] # Use the pre-mapped 0-based index
    rating = row['rating']
    return user_id, movie_id, rating

class SimpleNCF(nn.Module):
    def __init__(self, num_users, num_movies, embedding_dim=50, hidden_dims=[64, 32]):
        super(SimpleNCF, self).__init__()
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)

        layers = []
        input_dim = embedding_dim * 2
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(input_dim, hidden_dim))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.2))
            input_dim = hidden_dim

        layers.append(nn.Linear(input_dim, 1))
        self.mlp = nn.Sequential(*layers)

    def forward(self, user_ids, movie_ids):
        user_emb = self.user_embedding(user_ids)
        movie_emb = self.movie_embedding(movie_ids)
        x = torch.cat([user_emb, movie_emb], dim=1)
        return self.mlp(x).squeeze()

# Prepare data for NCF
def prepare_ncf_data(ratings):
    # Create user and movie mappings
    unique_users = sorted(ratings['user_id'].unique())
    unique_movies = sorted(ratings['movie_id'].unique())

    user_to_idx = {user: idx for idx, user in enumerate(unique_users)}
    movie_to_idx = {movie: idx for idx, movie in enumerate(unique_movies)}

    # Convert ratings
    ratings_processed = ratings.copy()
    ratings_processed['user_idx'] = ratings_processed['user_id'].map(user_to_idx)
    ratings_processed['movie_idx'] = ratings_processed['movie_id'].map(movie_to_idx)

    return ratings_processed, len(unique_users), len(unique_movies)

# Prepare data
ncf_ratings, num_users, num_movies = prepare_ncf_data(train_ratings)

print(f"NCF Data Prepared:")
print(f"Users: {num_users}, Movies: {num_movies}")
print(f"Training ratings: {len(ncf_ratings)}")

# Train the NCF model
def train_ncf_model(train_ratings, num_users, num_movies, epochs=10, batch_size=64):
    dataset = NCFDataset(train_ratings, num_users, num_movies)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    model = SimpleNCF(num_users, num_movies)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for batch_idx, (user_ids, movie_ids, ratings) in enumerate(dataloader):
            optimizer.zero_grad()
            predictions = model(user_ids, movie_ids)
            loss = criterion(predictions, ratings.float())
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}')

    return model

print("üöÄ Training Neural Collaborative Filtering Model...")
ncf_model = train_ncf_model(ncf_ratings, num_users, num_movies, epochs=10)
print("‚úÖ NCF Model Training Complete!")

# Generate recommendations with NCF
def ncf_recommendations(user_id, model, item_table, train_ratings, k=10):
    model.eval()

    # Get user index
    user_idx = user_id - 1

    # Get movies user hasn't rated
    rated_movies = train_ratings[train_ratings['user_id'] == user_id]['movie_id'].tolist()
    all_movies = item_table['movie_id'].tolist()
    unrated_movies = [movie for movie in all_movies if movie not in rated_movies]

    # Predict ratings for unrated movies
    scores = []
    with torch.no_grad():
        for movie_id in unrated_movies[:500]:  # Limit for speed
            movie_idx = movie_id - 1
            user_tensor = torch.tensor([user_idx])
            movie_tensor = torch.tensor([movie_idx])
            prediction = model(user_tensor, movie_tensor)
            scores.append((movie_id, prediction.item()))

    # Sort by predicted rating and get top K
    scores.sort(key=lambda x: x[1], reverse=True)
    return [movie_id for movie_id, score in scores[:k]]

# Test NCF recommendations
ncf_recs = ncf_recommendations(sample_user, ncf_model, item_table, train_ratings)

print(f"üß† NCF Recommendations for User {sample_user}:")
for i, movie_id in enumerate(ncf_recs[:10], 1):
    movie_title = item_table[item_table['movie_id'] == movie_id]['clean_title'].iloc[0]
    print(f"{i}. {movie_title}")

# Summary of Phase 1-3 Implementation
print("üéâ SUMMARY: Phases 1-3 Complete!")
print("=" * 50)
print("‚úÖ Phase 1: Data Collection & Enrichment")
print("   - Loaded MovieLens 100K dataset")
print("   - Created unified item table with genres")
print("   - Filtered cold users/items")
print("   - Extracted user and content features")
print("   - Saved processed data")

print("\n‚úÖ Phase 2: Baselines & Exploratory Analysis")
print("   - Performed comprehensive EDA")
print("   - Implemented 3 baselines:")
print("     ‚Ä¢ Popularity-based")
print("     ‚Ä¢ Item-based Collaborative Filtering")
print("     ‚Ä¢ Content-based filtering")
print("   - Evaluated baselines with Precision@K, Recall@K, HitRate@K")

print("\n‚úÖ Phase 3: Hybrid Recommendation Model")
print("   - Built Neural Collaborative Filtering (NCF) model")
print("   - Trained model on user-movie interactions")
print("   - Generated personalized recommendations")

"""**Phase 4:  Add Explainability (SHAP, attention)**"""

import shap
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Simple Feature Importance for Content-based Model
def explain_content_recommendation(user_id, movie_id, item_table, user_features, genre_cols):
    """Explain why a movie was recommended in content-based filtering"""

    # Get user preferences
    user_prefs = user_features[user_features['user_id'] == user_id]
    pref_cols = [f'pref_{genre}' for genre in genre_cols]
    user_pref_vector = user_prefs[pref_cols].values.flatten()

    # Get movie genres
    movie_genres = item_table[item_table['movie_id'] == movie_id][genre_cols].values.flatten()

    # Calculate contribution scores
    contributions = user_pref_vector * movie_genres
    feature_scores = list(zip(genre_cols, contributions))
    feature_scores = [(genre, score) for genre, score in feature_scores if score > 0]
    feature_scores.sort(key=lambda x: x[1], reverse=True)

    return feature_scores

# Test explanation for a content-based recommendation
sample_movie_id = content_recommendations[0]
content_explanation = explain_content_recommendation(
    sample_user, sample_movie_id, item_table, user_features, genre_cols
)

print(f"üéØ Explanation for Content-Based Recommendation:")
movie_title = item_table[item_table['movie_id'] == sample_movie_id]['clean_title'].iloc[0]
print(f"Movie: {movie_title}")
print("Top contributing genres:")
for genre, score in content_explanation[:5]:
    print(f"  ‚Ä¢ {genre}: {score:.3f}")

# SHAP Explanations for Simple Model
def create_simple_recommendation_model(train_ratings, item_table, user_features, genre_cols):
    """Create a simple linear model for SHAP explanations"""

    # Prepare training data
    train_data = []
    for _, rating in train_ratings.iterrows():
        user_id = rating['user_id']
        movie_id = rating['movie_id']

        # Get user features
        user_row = user_features[user_features['user_id'] == user_id]
        if user_row.empty:
            continue

        # Get user genre preferences
        pref_cols = [f'pref_{genre}' for genre in genre_cols]
        user_prefs = user_row[pref_cols].values.flatten()

        # Get movie genres
        movie_row = item_table[item_table['movie_id'] == movie_id]
        if movie_row.empty:
            continue
        movie_genres = movie_row[genre_cols].values.flatten()

        # Create interaction features
        interaction_features = user_prefs * movie_genres

        train_data.append({
            'features': interaction_features,
            'rating': rating['rating']
        })

    # Convert to arrays
    X = np.array([d['features'] for d in train_data])
    y = np.array([d['rating'] for d in train_data])

    # Train simple linear model
    model = LinearRegression()
    model.fit(X, y)

    return model, X

# Train simple model for SHAP
print("üìä Training simple model for SHAP explanations...")
simple_model, X_train = create_simple_recommendation_model(
    train_ratings.head(1000), item_table, user_features, genre_cols
)

# Initialize SHAP explainer
explainer = shap.Explainer(simple_model, X_train[:100])  # Use subset for speed

print("‚úÖ Simple model trained and SHAP explainer ready!")

# Generate SHAP Explanations
def generate_shap_explanation(user_id, movie_id, simple_model, explainer,
                            item_table, user_features, genre_cols):
    """Generate SHAP explanation for a user-movie pair"""

    # Get feature vector for this prediction
    user_row = user_features[user_features['user_id'] == user_id]
    movie_row = item_table[item_table['movie_id'] == movie_id]

    if user_row.empty or movie_row.empty:
        return None

    pref_cols = [f'pref_{genre}' for genre in genre_cols]
    user_prefs = user_row[pref_cols].values.flatten()
    movie_genres = movie_row[genre_cols].values.flatten()
    interaction_features = user_prefs * movie_genres

    # Get SHAP values
    shap_values = explainer(interaction_features.reshape(1, -1))

    # Get top contributing features
    feature_contributions = []
    for i, genre in enumerate(genre_cols):
        if interaction_features[i] > 0:  # Only include active features
            feature_contributions.append({
                'genre': genre,
                'contribution': shap_values.values[0][i],
                'user_pref': user_prefs[i],
                'movie_has_genre': movie_genres[i]
            })

    # Sort by absolute contribution
    feature_contributions.sort(key=lambda x: abs(x['contribution']), reverse=True)

    return feature_contributions, shap_values

# Test SHAP explanation
shap_result, shap_values = generate_shap_explanation(
    sample_user, sample_movie_id, simple_model, explainer,
    item_table, user_features, genre_cols
)

print(f"üéØ SHAP Explanation for Recommendation:")
print(f"User: {sample_user}, Movie: {movie_title}")
print("Top contributing factors:")
for i, contrib in enumerate(shap_result[:5], 1):
    print(f"{i}. {contrib['genre']}: {contrib['contribution']:.3f} (user preference: {contrib['user_pref']:.2f})")

# Layered Explanation System
def generate_layered_explanation(user_id, movie_id, explanation_type="short"):
    """Generate layered explanations: short, detailed, or technical"""

    movie_title = item_table[item_table['movie_id'] == movie_id]['clean_title'].iloc[0]

    if explanation_type == "short":
        # Short why (1-2 lines)
        content_expl = explain_content_recommendation(user_id, movie_id, item_table, user_features, genre_cols)
        top_genres = [genre for genre, score in content_expl[:2]]

        explanation = f"Recommended because you like {', '.join(top_genres)} movies."
        return explanation

    elif explanation_type == "detailed":
        # Detailed explanation with scores
        content_expl = explain_content_recommendation(user_id, movie_id, item_table, user_features, genre_cols)

        explanation = f"üé¨ {movie_title}\n"
        explanation += "Genre matching scores:\n"
        for genre, score in content_expl[:5]:
            explanation += f"  ‚Ä¢ {genre}: {score:.3f}\n"

        return explanation

    else:  # technical
        # Technical explanation with SHAP
        shap_result, _ = generate_shap_explanation(
            user_id, movie_id, simple_model, explainer,
            item_table, user_features, genre_cols
        )

        explanation = f"üîß Technical Explanation for {movie_title}:\n"
        explanation += "SHAP feature contributions:\n"
        for i, contrib in enumerate(shap_result[:5], 1):
            explanation += f"  {i}. {contrib['genre']}: {contrib['contribution']:.3f}\n"

        return explanation

# Test layered explanations
print("üìã LAYERED EXPLANATIONS DEMO")
print("=" * 40)

print("\n1. SHORT Explanation:")
short_expl = generate_layered_explanation(sample_user, sample_movie_id, "short")
print(short_expl)

print("\n2. DETAILED Explanation:")
detailed_expl = generate_layered_explanation(sample_user, sample_movie_id, "detailed")
print(detailed_expl)

print("\n3. TECHNICAL Explanation:")
technical_expl = generate_layered_explanation(sample_user, sample_movie_id, "technical")
print(technical_expl)

# Visual Explanation Dashboard
def plot_explanation_dashboard(user_id, movie_id):
    """Create visual explanations for a recommendation"""

    # Get explanations
    content_expl = explain_content_recommendation(user_id, movie_id, item_table, user_features, genre_cols)
    shap_result, _ = generate_shap_explanation(
        user_id, movie_id, simple_model, explainer,
        item_table, user_features, genre_cols
    )

    # Create subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # Plot 1: Content-based feature importance
    genres_content = [genre for genre, score in content_expl[:8]]
    scores_content = [score for genre, score in content_expl[:8]]

    ax1.barh(genres_content, scores_content, color='skyblue')
    ax1.set_xlabel('Feature Importance Score')
    ax1.set_title('Content-Based Feature Importance')
    ax1.grid(axis='x', alpha=0.3)

    # Plot 2: SHAP values
    genres_shap = [contrib['genre'] for contrib in shap_result[:8]]
    contributions = [contrib['contribution'] for contrib in shap_result[:8]]

    colors = ['green' if x > 0 else 'red' for x in contributions]
    ax2.barh(genres_shap, contributions, color=colors)
    ax2.set_xlabel('SHAP Value (Impact on Rating)')
    ax2.set_title('SHAP Feature Contributions')
    ax2.axvline(x=0, color='black', linestyle='-', alpha=0.3)
    ax2.grid(axis='x', alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Print summary
    movie_title = item_table[item_table['movie_id'] == movie_id]['clean_title'].iloc[0]
    print(f"üìä Explanation Dashboard for: {movie_title}")
    print(f"User ID: {user_id}")

# Test visual dashboard
print("üìà Generating Visual Explanation Dashboard...")
plot_explanation_dashboard(sample_user, sample_movie_id)

"""**Phase 5: Comprehensive Evaluation**"""

# Extended Offline Evaluation
def comprehensive_offline_evaluation(train_ratings, test_ratings, item_table, user_features, genre_cols, k=10):
    """Comprehensive evaluation of all models"""

    models = {
        'popularity': lambda user_id: popularity_baseline(train_ratings, k)[0],
        'item_cf': lambda user_id: item_based_cf(train_ratings, item_table, genre_cols, user_id, k),
        'content': lambda user_id: content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features, k),
        'ncf': lambda user_id: ncf_recommendations(user_id, ncf_model, item_table, train_ratings, k)
    }

    metrics = {
        model: {
            'precision': [], 'recall': [], 'hit_rate': [],
            'ndcg': [], 'diversity': [], 'novelty': []
        } for model in models
    }

    # Sample users for evaluation
    test_users = test_ratings['user_id'].unique()[:30]  # Limit for demo

    for user_id in test_users:
        user_test_movies = test_ratings[test_ratings['user_id'] == user_id]['movie_id'].tolist()

        if not user_test_movies:
            continue

        for model_name, model_func in models.items():
            try:
                recommendations = model_func(user_id)

                # Basic metrics
                hits = len(set(recommendations) & set(user_test_movies))
                precision = hits / k
                recall = hits / len(user_test_movies)
                hit_rate = 1 if hits > 0 else 0

                # NDCG
                dcg = 0
                for i, movie_id in enumerate(recommendations):
                    if movie_id in user_test_movies:
                        dcg += 1 / np.log2(i + 2)
                idcg = sum(1 / np.log2(i + 2) for i in range(min(len(user_test_movies), k)))
                ndcg = dcg / idcg if idcg > 0 else 0

                # Diversity (genre diversity of recommendations)
                rec_genres = []
                for movie_id in recommendations:
                    movie_genres = item_table[item_table['movie_id'] == movie_id][genre_cols]
                    active_genres = [genre for genre in genre_cols if movie_genres[genre].iloc[0] == 1]
                    rec_genres.extend(active_genres)
                diversity = len(set(rec_genres)) / len(rec_genres) if rec_genres else 0

                # Novelty (inverse of popularity)
                novelty_scores = []
                for movie_id in recommendations:
                    popularity = len(train_ratings[train_ratings['movie_id'] == movie_id])
                    novelty = 1 / (1 + popularity)  # Avoid division by zero
                    novelty_scores.append(novelty)
                novelty = np.mean(novelty_scores) if novelty_scores else 0

                # Store metrics
                metrics[model_name]['precision'].append(precision)
                metrics[model_name]['recall'].append(recall)
                metrics[model_name]['hit_rate'].append(hit_rate)
                metrics[model_name]['ndcg'].append(ndcg)
                metrics[model_name]['diversity'].append(diversity)
                metrics[model_name]['novelty'].append(novelty)

            except Exception as e:
                continue

    # Calculate average metrics
    results = {}
    for model_name in metrics:
        if metrics[model_name]['precision']:
            results[model_name] = {
                'Precision@K': np.mean(metrics[model_name]['precision']),
                'Recall@K': np.mean(metrics[model_name]['recall']),
                'HitRate@K': np.mean(metrics[model_name]['hit_rate']),
                'NDCG@K': np.mean(metrics[model_name]['ndcg']),
                'Diversity': np.mean(metrics[model_name]['diversity']),
                'Novelty': np.mean(metrics[model_name]['novelty'])
            }

    return pd.DataFrame(results).T

print("üß™ Running Comprehensive Offline Evaluation...")
comprehensive_results = comprehensive_offline_evaluation(
    train_ratings, test_ratings, item_table, user_features, genre_cols
)

print("üìä COMPREHENSIVE EVALUATION RESULTS:")
print(comprehensive_results.round(4))

# Explanation Quality Metrics
def evaluate_explanation_quality(user_features, item_table, genre_cols, n_users=10):
    """Evaluate explanation quality metrics"""

    print("üîç Evaluating Explanation Quality...")

    fidelity_scores = []
    stability_scores = []
    sufficiency_scores = []

    # Sample users for evaluation
    sample_users = user_features['user_id'].sample(min(n_users, len(user_features))).tolist()

    for user_id in sample_users:
        try:
            # Get user's top preferred genres
            pref_cols = [f'pref_{genre}' for genre in genre_cols]
            user_prefs = user_features[user_features['user_id'] == user_id][pref_cols].values.flatten()
            top_genres_idx = np.argsort(user_prefs)[-3:]  # Top 3 genres
            top_genres = [genre_cols[i] for i in top_genres_idx]

            # Get recommendations
            recommendations = content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features, k=5)

            for movie_id in recommendations[:2]:  # Evaluate first 2 recommendations
                # Fidelity: Does explanation match model reasoning?
                explanation = explain_content_recommendation(user_id, movie_id, item_table, user_features, genre_cols)
                top_explanation_genres = [genre for genre, score in explanation[:3]]

                # Check if top explained genres match user's top preferences
                fidelity = len(set(top_explanation_genres) & set(top_genres)) / 3
                fidelity_scores.append(fidelity)

                # Stability: Small perturbations in user preferences
                perturbed_prefs = user_prefs + np.random.normal(0, 0.1, len(user_prefs))
                perturbed_prefs = np.clip(perturbed_prefs, 0, 5)

                # Get explanation with perturbed preferences
                user_features_perturbed = user_features.copy()
                user_features_perturbed.loc[user_features_perturbed['user_id'] == user_id, pref_cols] = perturbed_prefs

                explanation_perturbed = explain_content_recommendation(user_id, movie_id, item_table, user_features_perturbed, genre_cols)
                top_explanation_perturbed = [genre for genre, score in explanation_perturbed[:3]]

                stability = len(set(top_explanation_genres) & set(top_explanation_perturbed)) / 3
                stability_scores.append(stability)

                # Sufficiency: Remove top features and check score drop
                original_score = sum(score for genre, score in explanation)

                # Remove top feature and recalculate
                if len(explanation) > 1:
                    explanation_without_top = explanation[1:]
                    new_score = sum(score for genre, score in explanation_without_top)
                    sufficiency = new_score / original_score if original_score > 0 else 0
                    sufficiency_scores.append(sufficiency)

        except Exception as e:
            continue

    # Calculate average metrics
    results = {
        'Fidelity': np.mean(fidelity_scores) if fidelity_scores else 0,
        'Stability': np.mean(stability_scores) if stability_scores else 0,
        'Sufficiency': np.mean(sufficiency_scores) if sufficiency_scores else 0
    }

    return results

# Evaluate explanation quality
explanation_metrics = evaluate_explanation_quality(user_features, item_table, genre_cols)

print("üìã EXPLANATION QUALITY METRICS:")
for metric, score in explanation_metrics.items():
    print(f"{metric}: {score:.4f}")

# Comparative Analysis Visualization
def plot_comparative_analysis(comprehensive_results):
    """Create comparative visualization of all models"""

    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    axes = axes.flatten()

    metrics_to_plot = ['Precision@K', 'Recall@K', 'HitRate@K', 'NDCG@K', 'Diversity', 'Novelty']

    for i, metric in enumerate(metrics_to_plot):
        if metric in comprehensive_results.columns:
            models = comprehensive_results.index
            scores = comprehensive_results[metric]

            bars = axes[i].bar(models, scores, color=['skyblue', 'lightgreen', 'salmon', 'gold'])
            axes[i].set_title(f'{metric} Comparison')
            axes[i].set_ylabel(metric)
            axes[i].tick_params(axis='x', rotation=45)

            # Add value labels on bars
            for bar, score in zip(bars, scores):
                height = bar.get_height()
                axes[i].text(bar.get_x() + bar.get_width()/2., height,
                           f'{score:.3f}', ha='center', va='bottom')

    plt.tight_layout()
    plt.show()

# Create comparative visualization
print("üìà Generating Comparative Analysis...")
plot_comparative_analysis(comprehensive_results)

# Model Performance Summary
def generate_performance_summary(comprehensive_results, explanation_metrics):
    """Generate comprehensive performance summary"""

    print("üéØ COMPREHENSIVE PERFORMANCE SUMMARY")
    print("=" * 50)

    # Find best model for each metric
    best_models = {}
    for metric in comprehensive_results.columns:
        best_model = comprehensive_results[metric].idxmax()
        best_score = comprehensive_results[metric].max()
        best_models[metric] = (best_model, best_score)

    print("\nüèÜ BEST PERFORMING MODELS:")
    for metric, (model, score) in best_models.items():
        print(f"  {metric}: {model} ({score:.4f})")

    print("\nüìä OVERALL RANKING (by NDCG@K):")
    ranked_models = comprehensive_results['NDCG@K'].sort_values(ascending=False)
    for model, score in ranked_models.items():
        print(f"  {model}: {score:.4f}")

    print("\nüîç EXPLANATION QUALITY:")
    for metric, score in explanation_metrics.items():
        print(f"  {metric}: {score:.4f}")

    print("\nüí° RECOMMENDATIONS:")
    if comprehensive_results.loc['ncf', 'NDCG@K'] > 0.1:
        print("  ‚Ä¢ NCF shows good performance - consider for deployment")
    if explanation_metrics['Fidelity'] > 0.6:
        print("  ‚Ä¢ Explanations have good fidelity - trustworthy for users")
    if comprehensive_results['Diversity'].mean() > 0.5:
        print("  ‚Ä¢ Models provide diverse recommendations")
    if comprehensive_results['Novelty'].mean() > 0.3:
        print("  ‚Ä¢ Good novelty - not just popular items")

# Generate summary
generate_performance_summary(comprehensive_results, explanation_metrics)

# Save Evaluation Results
def save_evaluation_results(comprehensive_results, explanation_metrics):
    """Save all evaluation results for future reference"""

    # Create results directory
    os.makedirs('/content//drive/MyDrive/results', exist_ok=True)

    # Save comprehensive results
    comprehensive_results.to_csv('/content/drive/MyDrive/results/comprehensive_evaluation.csv')

    # Save explanation metrics
    explanation_df = pd.DataFrame([explanation_metrics])
    explanation_df.to_csv('/content//drive/MyDrive/results/explanation_quality.csv', index=False)

    # Save summary report
    with open('/content//drive/MyDrive/results/evaluation_summary.txt', 'w') as f:
        f.write("MOVIE RECOMMENDATION SYSTEM EVALUATION SUMMARY\n")
        f.write("=" * 50 + "\n\n")

        f.write("COMPREHENSIVE RESULTS:\n")
        f.write(comprehensive_results.round(4).to_string())
        f.write("\n\n")

        f.write("EXPLANATION QUALITY:\n")
        for metric, score in explanation_metrics.items():
            f.write(f"{metric}: {score:.4f}\n")

    print("üíæ Evaluation results saved to /content//drive/MyDrive/results/")
    print("   - comprehensive_evaluation.csv")
    print("   - explanation_quality.csv")
    print("   - evaluation_summary.txt")

# Save results
save_evaluation_results(comprehensive_results, explanation_metrics)

"""**Phase 6: Experiments & Ablation Studies**"""

# Model Comparison Experiment
def run_model_comparison_experiment():
    """Compare all models across different K values"""

    k_values = [5, 10, 15, 20]
    results = {}

    for k in k_values:
        print(f"üß™ Testing with K={k}...")
        k_results = comprehensive_offline_evaluation(
            train_ratings, test_ratings, item_table, user_features, genre_cols, k=k
        )
        results[k] = k_results

    return results

print("Running model comparison experiment...")
k_comparison_results = run_model_comparison_experiment()

# Display results
print("\nüìä MODEL COMPARISON ACROSS K VALUES:")
for k, result_df in k_comparison_results.items():
    print(f"\nK={k}:")
    print(result_df['NDCG@K'].round(4))

# Ablation Study - Feature Importance
def run_ablation_study():
    """Study the impact of different feature types"""

    print("üîç Running Ablation Study...")

    # Original model (all features)
    original_results = comprehensive_offline_evaluation(
        train_ratings, test_ratings, item_table, user_features, genre_cols, k=10
    )

    # Test without user demographic features
    user_features_no_demo = user_features.drop(['age', 'gender'] +
                                              [col for col in user_features.columns
                                               if 'occupation' in col], axis=1, errors='ignore')

    no_demo_results = comprehensive_offline_evaluation(
        train_ratings, test_ratings, item_table, user_features_no_demo, genre_cols, k=10
    )

    # Test with only top 5 genres
    top_genres = ['Drama', 'Comedy', 'Action', 'Thriller', 'Romance']
    limited_genres = [g for g in genre_cols if g in top_genres]

    limited_results = comprehensive_offline_evaluation(
        train_ratings, test_ratings, item_table, user_features, limited_genres, k=10
    )

    return {
        'original': original_results.loc['content', 'NDCG@K'],
        'no_demographics': no_demo_results.loc['content', 'NDCG@K'],
        'limited_genres': limited_results.loc['content', 'NDCG@K']
    }

# Run ablation study
ablation_results = run_ablation_study()

print("üìâ ABLATION STUDY RESULTS:")
for condition, score in ablation_results.items():
    print(f"  {condition}: NDCG@10 = {score:.4f}")

# Calculate performance drop
original_score = ablation_results['original']
print(f"\nüìä PERFORMANCE IMPACT:")
print(f"  Without demographics: {((ablation_results['no_demographics'] - original_score) / original_score * 100):+.1f}%")
print(f"  Limited genres: {((ablation_results['limited_genres'] - original_score) / original_score * 100):+.1f}%")

# Cold-Start Scenario Testing
def test_cold_start_scenarios():
    """Test performance on cold-start users and items"""

    print("‚ùÑÔ∏è Testing Cold-Start Scenarios...")

    # Cold users (users with very few ratings)
    cold_user_threshold = 10
    user_rating_counts = train_ratings['user_id'].value_counts()
    cold_users = user_rating_counts[user_rating_counts <= cold_user_threshold].index.tolist()

    # Cold items (items with very few ratings)
    cold_item_threshold = 5
    item_rating_counts = train_ratings['movie_id'].value_counts()
    cold_items = item_rating_counts[item_rating_counts <= cold_item_threshold].index.tolist()

    print(f"Cold users: {len(cold_users)}")
    print(f"Cold items: {len(cold_items)}")

    # Test cold user performance
    cold_user_metrics = []
    for user_id in cold_users[:10]:  # Test first 10 cold users
        try:
            # Test content-based (should work better for cold start)
            content_recs = content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features, k=5)
            cf_recs = item_based_cf(train_ratings, item_table, genre_cols, user_id, k=5)

            # Get test movies for this user
            user_test_movies = test_ratings[test_ratings['user_id'] == user_id]['movie_id'].tolist()

            if user_test_movies:
                content_hits = len(set(content_recs) & set(user_test_movies))
                cf_hits = len(set(cf_recs) & set(user_test_movies))

                cold_user_metrics.append({
                    'user_id': user_id,
                    'content_hit_rate': 1 if content_hits > 0 else 0,
                    'cf_hit_rate': 1 if cf_hits > 0 else 0
                })
        except:
            continue

    if cold_user_metrics:
        cold_user_df = pd.DataFrame(cold_user_metrics)
        content_success_rate = cold_user_df['content_hit_rate'].mean()
        cf_success_rate = cold_user_df['cf_hit_rate'].mean()

        print(f"\nüéØ Cold User Success Rates:")
        print(f"  Content-based: {content_success_rate:.3f}")
        print(f"  Collaborative Filtering: {cf_success_rate:.3f}")

        return content_success_rate, cf_success_rate

    return 0, 0

# Run cold-start tests
cold_start_results = test_cold_start_scenarios()

# Explanation Method Comparison
def compare_explanation_methods():
    """Compare different explanation methods"""

    print("üîç Comparing Explanation Methods...")

    sample_size = 5
    test_users = user_features['user_id'].sample(sample_size).tolist()

    methods_comparison = {
        'feature_importance': [],
        'shap': [],
        'simple_template': []
    }

    for user_id in test_users:
        try:
            # Get a recommendation
            recs = content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features, k=1)
            if not recs:
                continue

            movie_id = recs[0]

            # Generate explanations with different methods
            feature_expl = explain_content_recommendation(user_id, movie_id, item_table, user_features, genre_cols)
            shap_expl, _ = generate_shap_explanation(user_id, movie_id, simple_model, explainer, item_table, user_features, genre_cols)
            template_expl = generate_layered_explanation(user_id, movie_id, "short")

            # Score explanations (simplified)
            feature_score = len([g for g, s in feature_expl if s > 0.1])
            shap_score = len([c for c in shap_expl if abs(c['contribution']) > 0.01])
            template_score = len(template_expl.split())  # Simplicity score

            methods_comparison['feature_importance'].append(feature_score)
            methods_comparison['shap'].append(shap_score)
            methods_comparison['simple_template'].append(template_score)

        except Exception as e:
            continue

    # Calculate average scores
    avg_scores = {}
    for method, scores in methods_comparison.items():
        if scores:
            avg_scores[method] = np.mean(scores)

    return avg_scores

# Compare explanation methods
explanation_comparison = compare_explanation_methods()

print("üìã EXPLANATION METHOD COMPARISON:")
for method, score in explanation_comparison.items():
    print(f"  {method}: {score:.2f}")

print("\nüí° Interpretation:")
print("  ‚Ä¢ Higher feature_importance: More features used in explanation")
print("  ‚Ä¢ Higher shap: More detailed technical explanation")
print("  ‚Ä¢ Lower simple_template: More concise user-friendly explanation")

# Save Experiment Results
def save_experiment_results(k_comparison_results, ablation_results, cold_start_results, explanation_comparison):
    """Save all experiment results"""

    os.makedirs('/content/drive/MyDrive/experiments', exist_ok=True)

    # Save K comparison results
    k_comparison_df = pd.concat(k_comparison_results, names=['K', 'Model'])
    k_comparison_df.to_csv('/content//drive/MyDrive/experiments/k_comparison.csv')

    # Save ablation study
    ablation_df = pd.DataFrame([ablation_results])
    ablation_df.to_csv('/content//drive/MyDrive/experiments/ablation_study.csv')

    # Save cold start results
    cold_start_df = pd.DataFrame({
        'content_success_rate': [cold_start_results[0]],
        'cf_success_rate': [cold_start_results[1]]
    })
    cold_start_df.to_csv('/content//drive/MyDrive/experiments/cold_start.csv', index=False)

    # Save explanation comparison
    explanation_df = pd.DataFrame([explanation_comparison])
    explanation_df.to_csv('/content//drive/MyDrive/experiments/explanation_comparison.csv', index=False)

    print("üíæ Experiment results saved to /content/drive/MyDrive//experiments/")

# Save all experiment results
save_experiment_results(k_comparison_results, ablation_results, cold_start_results, explanation_comparison)

"""# Testing Phase

**Get Recommendations for Any User ID**
"""

print("üé¨ MOVIE RECOMMENDATION SYSTEM - USER QUERY TOOL")
print("=" * 50)

# === Test Code: Compare Recommendations For Multiple Users ===
import pandas as pd

# Define sample users to test
sample_users = [224, 102, 600]  # Change or expand this list as you wish
top_n = 5  # Number of top recommendations to display per user/method

# Collect recommendation results
test_rows = []
for user_id in sample_users:
    # Popularity baseline is independent of user
    pop_recs = popularity_baseline(train_ratings)[0][:top_n]
    pop_titles = [item_table[item_table["movie_id"]==mid]["clean_title"].values[0] for mid in pop_recs]

    # Item-based Collaborative Filtering
    item_cf_recs = item_based_cf(train_ratings, item_table, genre_cols, user_id)[:top_n]
    item_cf_titles = [item_table[item_table["movie_id"]==mid]["clean_title"].values[0] for mid in item_cf_recs]

    # Content-based Filtering
    content_recs = content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features)[:top_n]
    content_titles = [item_table[item_table["movie_id"]==mid]["clean_title"].values[0] for mid in content_recs]

    # Neural Collaborative Filtering
    ncf_recs = ncf_recommendations(user_id, ncf_model, item_table, train_ratings)[:top_n]
    ncf_titles = [item_table[item_table["movie_id"]==mid]["clean_title"].values[0] for mid in ncf_recs]

    # Gather results for comparison
    for i in range(top_n):
        test_rows.append({
            'User': user_id,
            'Rank': i+1,
            'Popularity': pop_titles[i] if i < len(pop_titles) else '',
            'Item-CF': item_cf_titles[i] if i < len(item_cf_titles) else '',
            'Content-Based': content_titles[i] if i < len(content_titles) else '',
            'NCF': ncf_titles[i] if i < len(ncf_titles) else ''
        })

# Display as DataFrame (readable table)
test_df = pd.DataFrame(test_rows)
print(test_df)

# === Visualization Code: Show and Explain Recommendations for Test Users ===

import matplotlib.pyplot as plt

def explain_item_cf(user_id, movie_id):
    """Provide a basic explanation for item-based CF (customize for your logic)."""
    # Often: Most similar to user's highly-rated movies
    return f"Recommended because it's similar to movies user {user_id} rated highly."

def explain_content_based(user_id, movie_id):
    """Basic explanation for content-based filtering (customize for your logic)."""
    # Often: Shares genres/features with user's history
    return f"Recommended for user {user_id} because it matches their favorite genres/features."

def explain_ncf(user_id, movie_id, ncf_model=None):
    """Basic explanation for NCF (customize if using XAI for deep models)."""
    return f"Personalized neural recommendation for user {user_id} (latent features)."

# Define same users as before
sample_users = [224, 102, 600]
top_n = 5

for user_id in sample_users:
    pop_recs = popularity_baseline(train_ratings)[0][:top_n]
    item_cf_recs = item_based_cf(train_ratings, item_table, genre_cols, user_id)[:top_n]
    content_recs = content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features)[:top_n]
    ncf_recs = ncf_recommendations(user_id, ncf_model, item_table, train_ratings)[:top_n]

    labels = [
        item_table[item_table["movie_id"]==mid]["clean_title"].values[0] for mid in pop_recs
    ]
    models = ["Popularity", "Item CF", "Content-Based", "NCF"]
    rec_lists = [pop_recs, item_cf_recs, content_recs, ncf_recs]

    # Plot each recommendation list as bar chart (score or dummy rank)
    fig, axs = plt.subplots(1, 4, figsize=(22, 5))
    for ax, model, recs in zip(axs, models, rec_lists):
        movie_titles = [item_table[item_table["movie_id"]==mid]["clean_title"].values[0] for mid in recs]
        # Dummy "scores" (highest rank at top)
        ax.barh(range(top_n)[::-1], range(top_n), color='skyblue')
        ax.set_yticks(range(top_n)[::-1])
        ax.set_yticklabels(movie_titles)
        ax.set_title(f"{model} for User {user_id}")
        ax.invert_yaxis()
    plt.tight_layout()
    plt.show()

    # Explanations
    print(f"\nExplanations of top recommendations for user {user_id}:\n")
    print("Popularity:")
    for i, mid in enumerate(pop_recs):
        title = item_table[item_table["movie_id"]==mid]["clean_title"].values[0]
        print(f"  {i+1}. {title}: Most watched by all users.")

    print("Item-based CF:")
    for i, mid in enumerate(item_cf_recs):
        title = item_table[item_table["movie_id"]==mid]["clean_title"].values[0]
        print(f"  {i+1}. {title}: {explain_item_cf(user_id, mid)}")

    print("Content-based Filtering:")
    for i, mid in enumerate(content_recs):
        title = item_table[item_table["movie_id"]==mid]["clean_title"].values[0]
        print(f"  {i+1}. {title}: {explain_content_based(user_id, mid)}")

    print("NCF:")
    for i, mid in enumerate(ncf_recs):
        title = item_table[item_table["movie_id"]==mid]["clean_title"].values[0]
        print(f"  {i+1}. {title}: {explain_ncf(user_id, mid)}")

    print("\n"+"="*60+"\n")

# === Visualization Code with Genre-based Explanations ===

import matplotlib.pyplot as plt

def favorite_genres_for_user(user_id, ratings, movies, genre_colnames, topk=3):
    """Returns user's top genres (based on top-rated movies in their history)"""
    user_movies = ratings[ratings['user_id'] == user_id].merge(movies, on='movie_id')
    genre_scores = {}
    for _, row in user_movies.iterrows():
        for g in genre_colnames:
            if row[g]:
                genre_scores[g] = genre_scores.get(g, 0) + row['rating']
    # Sort by summed ratings
    fav = sorted(genre_scores.items(), key=lambda x: -x[1])
    return [g for g,_ in fav[:topk]]

def genre_overlap_text(user_genres, movie_row, genre_colnames):
    overlap = [g for g in user_genres if movie_row[g]]
    if overlap:
        return f"Matches user's favorite genres: {', '.join(overlap)}"
    else:
        return f"Different from user's top genres"

def explain_content_based(user_id, movie_row, user_top_genres, genre_cols):
    """Explain recommendation based on genre overlap."""
    return genre_overlap_text(user_top_genres, movie_row, genre_cols)

def explain_item_cf(user_id, movie_row, user_top_genres, genre_cols):
    """Explain Item CF: use genre overlap for interpretability."""
    return genre_overlap_text(user_top_genres, movie_row, genre_cols)

def explain_ncf(user_id, movie_row):
    return "Recommended based on learned complex user preferences (latent features)"

# Sample users and top_n as before
sample_users = [224, 102, 600]
top_n = 5

for user_id in sample_users:
    pop_recs = popularity_baseline(train_ratings)[0][:top_n]
    item_cf_recs = item_based_cf(train_ratings, item_table, genre_cols, user_id)[:top_n]
    content_recs = content_based_filtering(user_id, train_ratings, item_table, genre_cols, user_features)[:top_n]
    ncf_recs = ncf_recommendations(user_id, ncf_model, item_table, train_ratings)[:top_n]

    models = ["Popularity", "Item CF", "Content-Based", "NCF"]
    rec_lists = [pop_recs, item_cf_recs, content_recs, ncf_recs]

    # Find user's favorite genres (based on their history)
    user_top_genres = favorite_genres_for_user(user_id, train_ratings, item_table, genre_cols, topk=3)

    # Bar plot for each method
    fig, axs = plt.subplots(1, 4, figsize=(22,5))
    for ax, model, recs in zip(axs, models, rec_lists):
        movie_titles = [item_table[item_table["movie_id"] == mid]["clean_title"].values[0] for mid in recs]
        ax.barh(range(top_n)[::-1], range(top_n), color='skyblue')
        ax.set_yticks(range(top_n)[::-1])
        ax.set_yticklabels(movie_titles)
        ax.set_title(f"{model} for User {user_id}")
        ax.invert_yaxis()
    plt.tight_layout()
    plt.show()

    # Print detailed explanations for each recommendation
    print(f"\n--- User {user_id}: Top genres guessed: {', '.join(user_top_genres)} ---\n")
    for model, recs in zip(models, rec_lists):
        print(f"{model} Recommendations:")
        for i, mid in enumerate(recs):
            movie_row = item_table[item_table["movie_id"]==mid].iloc[0]
            title = movie_row["clean_title"]
            if model == "Popularity":
                expl = "Popular among most users."
            elif model == "Item CF":
                expl = explain_item_cf(user_id, movie_row, user_top_genres, genre_cols)
            elif model == "Content-Based":
                expl = explain_content_based(user_id, movie_row, user_top_genres, genre_cols)
            elif model == "NCF":
                expl = explain_ncf(user_id, movie_row)
            print(f"  {i+1}. {title}: {expl}")
        print()
    print("="*60)